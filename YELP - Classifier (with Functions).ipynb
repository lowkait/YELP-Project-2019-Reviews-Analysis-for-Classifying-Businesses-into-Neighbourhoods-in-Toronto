{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does language distinguish groups of businesses/people? What in the language? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does review comments help predict \n",
    "# Classify where the customers are from /business is located\n",
    "# Mutual information, discrete correlation between variables, correlation is linear,\n",
    "# mutual will pick up non-linear\n",
    "\n",
    "# correlation (linear, one causes the other) vs relationship (mutual, knowing one can allow for us to know the other)\n",
    "\n",
    "# didn't vs did not\n",
    "# names of companies ? What nouns to get rid of ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from tqdm import tqdm\n",
    "from collections import *\n",
    "import operator\n",
    "import itertools\n",
    "import dill\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import math\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# all words\n",
    "# words that occur more than once (get rid of ones that may be typos)\n",
    "# get rid of stop words\n",
    "# get rid of symbols ? \n",
    "# generator, defaultdict, get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'saveFile.pkl'\n",
    "#dill.dump_session(filename)\n",
    "#dill.load_session(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('business_text_stripped.csv', delimiter = ',')\n",
    "businesses = pd.read_csv(\"Businesses (1).csv\")\n",
    "bf = pd.read_csv('business_text_stripped.csv')\n",
    "toronto_map = gpd.read_file('Neighbourhoods.geojson')\n",
    "stop_words =  set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary of all words as long as they have more than 1 letter\n",
    "def everyWord(file, stop_words):\n",
    "    everyWord_counter = Counter()\n",
    "    everyWord_set = set()\n",
    "    for comment in tqdm(file['1'].values):\n",
    "        comment = [t.lower() for t in comment.split(\" \") if len(t) > 1]\n",
    "        for c in comment:\n",
    "            if c not in stop_words:\n",
    "                everyWord_set.add(c)\n",
    "        everyWord_counter.update(comment)\n",
    "    return everyWord_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out words that are digits, or appear less than 10 times\n",
    "def topktermFreq(everyWord, stop_words, k):\n",
    "    AllWords_stopDigits = Counter(everyWord)\n",
    "       \n",
    "    # create an ordered dictionary by decreasing term frequency\n",
    "    sorted_dict = OrderedDict(sorted(AllWords_stopDigits.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    top10000termFreq = dict(itertools.islice(sorted_dict.items(), k))\n",
    "    return top10000termFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10kdocFreq(file, topkTF):\n",
    "    # iterate through the comments\n",
    "    # make a set of words in the comments (so it only appears once)\n",
    "    top10000docFreq = defaultdict(int)\n",
    "    for comment in tqdm(file['1'].values):\n",
    "        comment = set(t.lower() for t in comment.split(\" \") if len(t) > 1)\n",
    "        for word in comment:\n",
    "            if word in top10kTF.keys():\n",
    "                top10000docFreq[word] += 1\n",
    "            else:\n",
    "                continue\n",
    "    return top10000docFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(file, top10kTF, top10kDF, stop_words):\n",
    "    TFIDF = np.zeros((32022,10000))\n",
    "    # for each of the comments (rows)\n",
    "    row_index = 0\n",
    "    # loop through each of the comments in the \n",
    "    for comment in tqdm(file['1'].values):\n",
    "        comment = [t.lower() for t in file.iloc[row_index][2].split(\" \") if len(t) > 1 and if t not in stop_words]\n",
    "        comment_counter = Counter(comment)\n",
    "        col_index = 0\n",
    "        # loop through the top 10k words\n",
    "        for word in top10kTF.keys():\n",
    "            if word in comment_counter.keys():\n",
    "                # equation\n",
    "                tf = comment_counter[word]/len(comment)\n",
    "                idf = math.log(32022/top10kDF[word])\n",
    "                TFIDF[row_index][col_index] = tf*idf\n",
    "                col_index += 1\n",
    "            else:\n",
    "                col_index += 1\n",
    "        row_index += 1\n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Classifier ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cos_sim: 32,022 x 32,022 matrix of dot prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was tested against Alex's code and was proven to work, therefore it is ok to test without testing this function\n",
    "def existing_neighbourhood_dictionary(businesses_file, neighbourhoods_file):\n",
    "    id=[]\n",
    "    latitude=[]\n",
    "    longitude=[]\n",
    "\n",
    "    for x in range(businesses_file.shape[0]):\n",
    "        id.append(businesses_file.iloc[x,13])\n",
    "        longitude.append(businesses_file.iloc[x,30])\n",
    "        latitude.append(businesses_file.iloc[x,31])\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        {'ID': id,\n",
    "         'Latitude': latitude,\n",
    "         'Longitude': longitude})\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Longitude, df.Latitude))\n",
    "    \n",
    "    business_neighbourhood = {}\n",
    "    b_names = businesses_file.iloc[:,13]\n",
    "    for key in b_names:\n",
    "        business_neighbourhood[key] = float('nan')\n",
    "        \n",
    "    for i in range(gdf.shape[0]): #for businesses\n",
    "        for j in range(neighbourhoods_file.shape[0]): # for neighbourhood\n",
    "            if (neighbourhoods_file.loc[j, 'geometry']).contains(gdf.iloc[i,3]) == True:\n",
    "                business_neighbourhood[businesses_file.iloc[i,13]] = neighbourhoods_file.iloc[j,6]\n",
    "    return business_neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_neighbourhood_dictionary(businesses, toronto_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(tfidf):\n",
    "    similarities = np.ones((len(tfidf),len(tfidf)))\n",
    "    for i in range(len(tfidf)):\n",
    "        a = tfidf[i]\n",
    "        for j in range(len(tfidf)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            else:\n",
    "                b = tfidf[j]\n",
    "                similarities[i][j] = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNearestNeighbours(comments_file, businesses_file, existing_neighbourhoods_dict, cos_sim, k): #want to specify the size\n",
    "    #return the kNearestNeighbours dictionary\n",
    "    kNearestNeighbours = {}\n",
    "    \n",
    "    # Have a dictionary stating the business and the neighbourhood, for ex. {2: 'A', 3: 'C', 6: 'C'}\n",
    "    kNeighbours = existing_neighbourhood_dictionary(businesses_file, neighbourhoods_file)\n",
    "    \n",
    "    for row in tqdm(file['0'].values):\n",
    "        unordered = {}\n",
    "        #first column is the angle between (cos_sim), second column is the label\n",
    "        for col in range(len(cos_sim)):\n",
    "            if cos_sim[row][col] != 1:\n",
    "                unordered[businesses_file.iloc[col,13]] = cos_sim[row][col]\n",
    "        # sort the dictionary by decreasing values (it does not include the value of 1)\n",
    "        ordered = OrderedDict(sorted(unordered.items(), key = operator.itemgetter(1), reverse = True))\n",
    "        # take the top k number in the dictionary\n",
    "        kNearest = dict(itertools.islice(ordered.items(), k))\n",
    "               \n",
    "        # Start adding up the results\n",
    "        tally = dict.fromkeys(set(kNeighbours.values()), 0)\n",
    "        for business in kNearest.keys():\n",
    "            tally[kNeighbours[business]] += 1/k\n",
    "        \n",
    "        tallyOrdered = dict(itertools.islice(OrderedDict(sorted(tally.items(), key = operator.itemgetter(1), reverse = True)).items(), 1))\n",
    "          \n",
    "        kNearestNeighbours[business] = list(tallyOrdered.keys())[0]\n",
    "        \n",
    "    return kNearestNeighbours\n",
    "        \n",
    "        \n",
    "# loop through rows of cos_sim (represent each business)\n",
    "# create a k-nearest neighbour dictionary, with zero keys and none for values\n",
    "# loop through the columns of the cos_sim\n",
    "# if the value at the [row][column] index is 1, then continue, it was the dot product with itself\n",
    "# else, remove the min key, add the current one, and update the value\n",
    "\n",
    "# once we have the k-nearest neighbour dictionary, we can start adding up the results\n",
    "# create a set of the results\n",
    "# make a tally dictionary with 0 values and keys of sets\n",
    "# loop through the labels (values from the previous k-nearest dictionary)\n",
    "# += 1/k for frequency\n",
    "# sorted dict to make the dictionary ordered by the highest to lowest freq\n",
    "\n",
    "# add this sorted dict to the overall dictionary "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

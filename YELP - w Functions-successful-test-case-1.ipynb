{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YELP Project 2019: Reviews Analysis for Classifying Businesses into Neighbourhoods in Toronto\n",
    "### Overall Question(s): Can language distinguish groups of businesses/people? What in the language? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[Section 1) Functions](#Section-1:-Functions) <br>\n",
    "[Section 2) TFIDF](#Section-2:-TFIDF) <br>\n",
    "[Section 3) Existing Neighbourhoods Dictionary ](#Section-3:-Existing-Neighbourhoods-Dictionary)<br>\n",
    "[Section 4) Cosine Similarity](#Section-4:-Cosine-Similarity)<br>\n",
    "[Section 5) K-Nearest Neighbours Classifier](#Section-5:-K-Nearest-Neighbours-Classifier)<br>\n",
    "[Section 6) Test Case 1](#Section-6:-Test-Case-1)<br>\n",
    "[Section 7) Findings/Results from Test Case 1](#Section-7:-Findings-and-Results-from-Test-Case-1) <br>\n",
    "[Section 8) Next Steps](#Section-8:-Next-Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from tqdm import tqdm\n",
    "from collections import *\n",
    "import operator\n",
    "import itertools\n",
    "import dill\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "from shapely.geometry import Point, Polygon\n",
    "import math\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Functions\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>\n",
    "\n",
    "__Input Variable Meanings:__\n",
    "- _file_ = file containing comments of the x-train dataset\n",
    "- *stop_words* = a set of stop words from the nltk package\n",
    "- _everyWord_ = a counter of all words from all business comments (return value from the everyWord function)\n",
    "- _k_ = the number of words to be used in the top k term frequency and top k document frequency counters, and used for the TFIDF and cosine similarity calculations.\n",
    "\n",
    "__1) everyWord(file, stop_words)__: Returns a counter of all words in all business comments that are not stop words. Used by the topktermFreq function to determine the words that appear the most. \n",
    "\n",
    "__2) topktermFreq(everyWord, stop_words, k)__: Returns a counter with k number of words, determined by the decreasing total term frequency, or total number of occurences across all businesses.\n",
    "\n",
    "__3) topkdocFreq(file, stop_words, k)__: Returns a counter using the words from the topktermFreq, with values corresponding to document frequency (number of documents the word appears in at least once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everyWord(file, stop_words):\n",
    "    everyWord_counter = Counter()\n",
    "    for comment in tqdm(file['1'].values):\n",
    "        comment = [t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if ((len(t) > 1) and (t.lower() not in stop_words))]\n",
    "        everyWord_counter.update(comment)\n",
    "    return everyWord_counter\n",
    "\n",
    "def topktermFreq(everyWord, stop_words, k):\n",
    "    AllWords_stop = Counter(everyWord)\n",
    "    sorted_dict = OrderedDict(sorted(AllWords_stop.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    topktermFreq = dict(itertools.islice(sorted_dict.items(), k))\n",
    "    return topktermFreq\n",
    "\n",
    "def topkdocFreq(file, stop_words, k):\n",
    "    allWordsinFile = everyWord(file, stop_words)\n",
    "    topkTF = topktermFreq(allWordsinFile, stop_words, k)\n",
    "    \n",
    "    topkdocFreq = defaultdict(int)\n",
    "    for comment in tqdm(file['1'].values):\n",
    "        comment = set(t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if len(t) > 1 and (t.lower() not in stop_words))\n",
    "        for word in comment:\n",
    "            if word in topkTF.keys():\n",
    "                topkdocFreq[word] += 1\n",
    "            else:\n",
    "                continue\n",
    "    return topkdocFreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: TFIDF\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>\n",
    "\n",
    "__Input Variable Meanings:__\n",
    "- *xtrain_file* = file containing all comments from x-train businesses\n",
    "- *test_file* = file containing all comments from test businesses\n",
    "- *topkDF* = dictionary with word as the key and document frequency as the value\n",
    "- *stop_words* = a set of stop words from the nltk package\n",
    "\n",
    "Returns an m x n matrix (m being the number of businesses per file, and n being the k number of words being analyzed, or words from topkTF and topkDF) with TFIDF scores as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_xtrain(xtrain_file, topkDF, stop_words):    \n",
    "    TFIDF = np.zeros((len(xtrain_file),len(topkDF)))\n",
    "    # for each of the comments (rows)\n",
    "    row_index = 0\n",
    "    # loop through each of the comments in the \n",
    "    for comment in tqdm(xtrain_file['1'].values):\n",
    "        \n",
    "        #comment contains all the words in the comments, but we are only interested in the 15\n",
    "        comment = [t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if ((len(t) > 1) and (t.lower() not in stop_words))]\n",
    "\n",
    "        # create a dictionary for all words\n",
    "        c_counter = Counter(comment)\n",
    "        \n",
    "        col_index = 0\n",
    "        # loop through the top 10k words\n",
    "        for word in topkDF.keys():\n",
    "            if word in c_counter.keys():\n",
    "                tf = c_counter[word]/len(comment)\n",
    "                idf = math.log10(len(xtrain_file)/topkDF[word])\n",
    "                TFIDF[row_index][col_index] = tf*idf\n",
    "                col_index += 1\n",
    "            else:\n",
    "                col_index += 1\n",
    "        row_index += 1\n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_test(xtrain_file, test_file, topkDF, stop_words):\n",
    "    TFIDF = np.zeros((len(test_file),len(topkDF)))\n",
    "    # for each of the comments (rows)\n",
    "    row_index = 0\n",
    "    # loop through each of the comments in the \n",
    "    for comment in tqdm(test_file['1'].values):\n",
    "        \n",
    "        #comment contains all the words in the comments, but we are only interested in the 15\n",
    "        comment = [t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if ((len(t) > 1) and (t.lower() not in stop_words))]\n",
    "\n",
    "        # create a dictionary for all words\n",
    "        c_counter = Counter(comment)\n",
    "        \n",
    "        col_index = 0\n",
    "        # loop through the top 10k words\n",
    "        for word in topkDF.keys():\n",
    "            if word in c_counter.keys():\n",
    "                tf = c_counter[word]/len(comment)\n",
    "                idf = math.log10(len(xtrain_file)/topkDF[word])\n",
    "                TFIDF[row_index][col_index] = tf*idf\n",
    "                col_index += 1\n",
    "            else:\n",
    "                col_index += 1\n",
    "        row_index += 1\n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Existing Neighbourhoods Dictionary\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>\n",
    "\n",
    "__Input Variable Meanings:__\n",
    "- *businesses_file* = file containing all information about all businesses\n",
    "- *neighbourhoods_file* = file containing all information about neighbourhoods in Toronto\n",
    "\n",
    "Returns a dictionary with the business ID as the key, and the neighbourhood it is actually in as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def existing_neighbourhood_dictionary(businesses_file, neighbourhoods_file):\n",
    "    id=[]\n",
    "    latitude=[]\n",
    "    longitude=[]\n",
    "\n",
    "    for x in range(businesses_file.shape[0]):\n",
    "        id.append(businesses_file.iloc[x,13])\n",
    "        longitude.append(businesses_file.iloc[x,30])\n",
    "        latitude.append(businesses_file.iloc[x,31])\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        {'ID': id,\n",
    "         'Latitude': latitude,\n",
    "         'Longitude': longitude})\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Longitude, df.Latitude))\n",
    "    \n",
    "    business_neighbourhood = {}\n",
    "    b_names = businesses_file.iloc[:,13]\n",
    "    for key in b_names:\n",
    "        business_neighbourhood[key] = float('nan')\n",
    "        \n",
    "    for i in range(gdf.shape[0]): #for businesses\n",
    "        for j in range(neighbourhoods_file.shape[0]): # for neighbourhood\n",
    "            if (neighbourhoods_file.loc[j, 'geometry']).contains(gdf.iloc[i,3]) == True:\n",
    "                business_neighbourhood[businesses_file.iloc[i,13]] = neighbourhoods_file.iloc[j,6]\n",
    "    return business_neighbourhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Cosine Similarity\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>\n",
    "\n",
    "__Input Variable Meanings:__\n",
    "- *tfidf_xtrain* = array of TFIDF scores for the x-train dataset\n",
    "- *tfidf_test* = array of TFIDF scores for the test dataset\n",
    "\n",
    "Returns an array of cosine similarities (calculated as the dot product between two vectors) between each of the test businesses and each of the x-train businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(tfidf_xtrain, tfidf_test):\n",
    "    similarities = np.zeros((len(tfidf_test),len(tfidf_xtrain)))\n",
    "    for i in range(len(tfidf_test)):\n",
    "        a = tfidf_test[i]\n",
    "        for j in range(len(tfidf_xtrain)):\n",
    "                b = tfidf_xtrain[j]\n",
    "                similarities[i][j] = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: K Nearest Neighbours Classifier\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>\n",
    "\n",
    "__Input Variable Meanings:__\n",
    "- *test_file* = file containing comments of the test businesses\n",
    "- *xtrain_comments_file* = file containing comments of the x-train dataset\n",
    "- *existing_neighbourhoods_xtrain* = dictionary with the business ID as the key, and the neighbourhood it is in as the value \n",
    "- *cos_sim* = array for the cosine similarities between the test businesses and the x-train dataset\n",
    "- *k* = the number of nearest neighbours to be looked at, which will be used in the final tally for each neighbourhood.\n",
    "\n",
    "Returns a dictionary with the test business ID as the key and the predicted neighbourhood as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNearestNeighbours(test_file, xtrain_comments_file, existing_neighbourhoods_xtrain, cos_sim, k): #want to specify the size\n",
    "    \n",
    "    kNearestNeighbours = {}\n",
    "    \n",
    "    # Have a dictionary stating the business and the neighbourhood, for ex. {2: 'A', 3: 'C', 6: 'C'}\n",
    "    \n",
    "    for row in tqdm(range(len(cos_sim))):\n",
    "        unordered = {}\n",
    "        for col in range(len(cos_sim[0])):\n",
    "            unordered[xtrain_comments_file.iloc[col,0]] = cos_sim[row][col]\n",
    "        # sort the dictionary by decreasing values\n",
    "        ordered = OrderedDict(sorted(unordered.items(), key = operator.itemgetter(1), reverse = True))\n",
    "        # take the top k number in the dictionary\n",
    "        kNearest = dict(itertools.islice(ordered.items(), k))\n",
    "        # kNearest dictionary is shown as \"business name: cosine similarity value\"\n",
    "        \n",
    "        # Start adding up the results\n",
    "        tally = dict.fromkeys(set(existing_neighbourhoods_xtrain.values()), 0)\n",
    "        for business in kNearest.keys():\n",
    "            if kNearest[business] != 0:\n",
    "                tally[existing_neighbourhoods_xtrain[business]] += 1\n",
    "        \n",
    "        tallyOrdered = dict(itertools.islice(OrderedDict(sorted(tally.items(), key = operator.itemgetter(1), reverse = True)).items(), 1))\n",
    "        kNearestNeighbours[test_file.iloc[row,0]] = list(tallyOrdered.keys())[0]\n",
    "        \n",
    "    return kNearestNeighbours\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Test Case 1\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_neighbourhoods = pd.read_csv('xtrain_neighbourhoods.csv')\n",
    "existing_neighbourhoods_xtrain = {}\n",
    "for i in range(xtrain_neighbourhoods.shape[0]):\n",
    "    existing_neighbourhoods_xtrain[xtrain_neighbourhoods.iloc[i,0]] = xtrain_neighbourhoods.iloc[i,1]\n",
    "    \n",
    "test_neighbourhoods = pd.read_csv('test_neighbourhoods.csv')\n",
    "neighbourhoods_test = {}\n",
    "for i in range(test_neighbourhoods.shape[0]):\n",
    "    neighbourhoods_test[test_neighbourhoods.iloc[i,0]] = test_neighbourhoods.iloc[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kait L\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "bf = pd.read_csv('test-case-comments.csv')\n",
    "stop_words =  list(stopwords.words('english')) \n",
    "cf = pd.read_csv('new-businesses-comments.csv')\n",
    "businesses = pd.read_csv(\"Businesses (1).csv\")\n",
    "data = pd.read_csv('business_text_stripped.csv')\n",
    "toronto_map = gpd.read_file('Neighbourhoods.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 4497.65it/s]\n",
      "100%|██████████| 9/9 [00:00<?, ?it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 4494.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1500.47it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 299.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Store 1': 'Food', 'Store 2': 'Clothes', 'Store 3': 'Clothes'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topkDF = topkdocFreq(bf, stop_words, 15)\n",
    "tfidf_xtrain = TFIDF_xtrain(bf, topkDF, stop_words)\n",
    "tfidf_test = TFIDF_test(bf, cf, topkDF, stop_words)\n",
    "cos_sim = cosineSimilarity(tfidf_xtrain, tfidf_test)\n",
    "kNearestNeighbours(cf, bf, existing_neighbourhoods_xtrain, cos_sim, 7)\n",
    "# Find the Accuracy of this compared to the actual answer\n",
    "# Go through the length of the kNearestNeighbours, if this matches the dictionary of actual results, sum += 1\n",
    "# Accuracy = sum/length of file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Findings and Results from Test Case 1\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>\n",
    "\n",
    "- **Code works on a small test case**: The code has been proven to work correctly on a small test case (when compared to going through the test case by hand). In this test case, the 'neighbourhoods' were replaced with store types for classification.\n",
    "\n",
    "- **Changing k for topkTF/topkDF**: The k value defines the number of words being used in the calculations based on decreasing total term frequency across all documents. The k for the topkDF was chosen to be 15. When changed to any number above 15, the results did not change. When k was changed to 14, there was also no change. However, when changed to any number equal to and below 13, the results changed. How can we find the best value for k? And at what point will the change in k affect the results significantly? \n",
    "\n",
    "- **Changing k for k-Nearest Neighbours**: There was no change to the results when the k value was changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: Next Steps\n",
    "[Return to Table of Contents](#Table-of-Contents) <br>\n",
    "\n",
    "- **Create an Accuracy function**: Create a function that outputs the accuracy of the kNearestNeighbours algorithm.\n",
    "- **Determining a suitable measure for k for topkDF**: When does the k-value begin to change the accuracy of the code and how is the accuracy affected? Run through a subset of the Yelp data to determine how the accuracy is affected for different k values.\n",
    "- **Determining whether k for k-nearest neighbours affects results significantly**: Similar to determining the suitable measure for k for topkDF, check how changing the k in k-nearest neighbours will affect the accuracy of the predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

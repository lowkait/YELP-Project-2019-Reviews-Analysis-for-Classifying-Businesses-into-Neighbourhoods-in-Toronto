{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pkl Save Files: <br>\n",
    "YELP-Test-10000-1-b.pkl = after 800 <br>\n",
    "YELP-Test-10000-1-c.pkl = after 1400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = \"YELP-Test-10000-1-c.pkl\"\n",
    "dill.dump_session(filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"YELP-Functions.py\"\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# # YELP Project 2019: Reviews Analysis for Classifying Businesses into Neighbourhoods in Toronto\n",
    "# ### Overall Question(s): Can language distinguish groups of businesses/people? What in the language? Why?\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from tqdm import tqdm\n",
    "from collections import *\n",
    "import operator\n",
    "import itertools\n",
    "import dill\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "from shapely.geometry import Point, Polygon\n",
    "import math\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "def everyWord(file, stop_words):\n",
    "    everyWord_counter = Counter()\n",
    "    for comment in tqdm(file['1'].values):\n",
    "        comment = [t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if ((len(t) > 1) and (t.lower() not in stop_words))]\n",
    "        everyWord_counter.update(comment)\n",
    "    return everyWord_counter\n",
    "\n",
    "def topktermFreq(everyWord, stop_words, k):\n",
    "    AllWords_stop = Counter(everyWord)\n",
    "    sorted_dict = OrderedDict(sorted(AllWords_stop.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    topktermFreq = dict(itertools.islice(sorted_dict.items(), k))\n",
    "    return topktermFreq\n",
    "\n",
    "def topkdocFreq(file, stop_words, k):\n",
    "    allWordsinFile = everyWord(file, stop_words)\n",
    "    topkTF = topktermFreq(allWordsinFile, stop_words, k)\n",
    "    topkdocFreq = defaultdict(int)\n",
    "    for comment in tqdm(file['1'].values):\n",
    "        comment = set(t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if len(t) > 1 and (t.lower() not in stop_words))\n",
    "        for word in comment:\n",
    "            if word in topkTF.keys():\n",
    "                topkdocFreq[word] += 1\n",
    "            else:\n",
    "                continue\n",
    "    return topkdocFreq\n",
    "\n",
    "def TFIDF_xtrain(xtrain_file, topkDF, stop_words):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    # for each of the comments (rows)\n",
    "    row_index = 0\n",
    "    # loop through each of the comments in the \n",
    "    for comment in tqdm(xtrain_file['1'].values):\n",
    "        #comment contains all the words in the comments, but we are only interested in the 15\n",
    "        comment = [t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if ((len(t) > 1) and (t.lower() not in stop_words))]\n",
    "        # create a dictionary for all words\n",
    "        c_counter = Counter(comment)        \n",
    "        col_index = 0\n",
    "        # loop through the top 10k words\n",
    "        for word in topkDF.keys():\n",
    "            if word in c_counter.keys():\n",
    "                row.append(row_index)\n",
    "                col.append(col_index)\n",
    "                data.append(round(((c_counter[word]/len(comment))*math.log10(len(xtrain_file)/topkDF[word])),5))\n",
    "                col_index += 1\n",
    "            else:\n",
    "                col_index += 1\n",
    "        row_index += 1\n",
    "    return sparse.coo_matrix((data,(row,col)), shape = (len(xtrain_file),len(topkDF))).toarray()\n",
    "\n",
    "def TFIDF_test(xtrain_file, test_file, topkDF, stop_words):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    # for each of the comments (rows)\n",
    "    row_index = 0\n",
    "    # loop through each of the comments in the \n",
    "    for comment in tqdm(test_file['1'].values):      \n",
    "        #comment contains all the words in the comments, but we are only interested in the 15\n",
    "        comment = [t.lower() for t in comment.replace('.',' ').replace(',',' ').split(\" \") if ((len(t) > 1) and (t.lower() not in stop_words))]\n",
    "        # create a dictionary for all words\n",
    "        c_counter = Counter(comment)  \n",
    "        col_index = 0\n",
    "        # loop through the top 10k words\n",
    "        for word in topkDF.keys():\n",
    "            if word in c_counter.keys():\n",
    "                row.append(row_index)\n",
    "                col.append(col_index)\n",
    "                data.append(round(((c_counter[word]/len(comment))*math.log10(len(xtrain_file)/topkDF[word])),5))\n",
    "                col_index += 1\n",
    "            else:\n",
    "                col_index += 1\n",
    "        row_index += 1\n",
    "    return sparse.coo_matrix((data,(row,col)), shape = (len(test_file),len(topkDF))).toarray()\n",
    "\n",
    "\n",
    "def existing_neighbourhood_dictionary(businesses_file, neighbourhoods_file):\n",
    "    id=[]\n",
    "    latitude=[]\n",
    "    longitude=[]\n",
    "    for x in range(businesses_file.shape[0]):\n",
    "        id.append(businesses_file.iloc[x,13])\n",
    "        longitude.append(businesses_file.iloc[x,30])\n",
    "        latitude.append(businesses_file.iloc[x,31])  \n",
    "    df = pd.DataFrame(\n",
    "        {'ID': id,\n",
    "         'Latitude': latitude,\n",
    "         'Longitude': longitude})\n",
    "    gdf = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Longitude, df.Latitude))    \n",
    "    business_neighbourhood = {}\n",
    "    b_names = businesses_file.iloc[:,13]\n",
    "    for key in b_names:\n",
    "        business_neighbourhood[key] = float('nan')      \n",
    "    for i in range(gdf.shape[0]): #for businesses\n",
    "        for j in range(neighbourhoods_file.shape[0]): # for neighbourhood\n",
    "            if (neighbourhoods_file.loc[j, 'geometry']).contains(gdf.iloc[i,3]) == True:\n",
    "                business_neighbourhood[businesses_file.iloc[i,13]] = neighbourhoods_file.iloc[j,6]\n",
    "    return business_neighbourhood\n",
    "\n",
    "def official_neighbourhoods(businesses_file):\n",
    "    neighbourhood_official = {}\n",
    "    for x in tqdm(range(businesses_file.shape[0])):\n",
    "        neighbourhood_official[(businesses_file.iloc[x,13])] = businesses_file.iloc[x,29]\n",
    "    return neighbourhood_official\n",
    "\n",
    "def cosineSimilarity(tfidf_xtrain, tfidf_test):\n",
    "    similarities = np.zeros((len(tfidf_test),len(tfidf_xtrain)))\n",
    "    for i in tqdm(range(tfidf_test.shape[0])):\n",
    "        a = tfidf_test[i]\n",
    "        for j in range(tfidf_xtrain.shape[0]):\n",
    "                b = tfidf_xtrain[j]\n",
    "                cosinesimilarity = round(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)), 1)\n",
    "                if cosinesimilarity == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    similarities[i][j] = cosinesimilarity\n",
    "    return similarities\n",
    "\n",
    "def kNearestNeighbours(test_file, xtrain_comments_file, existing_neighbourhoods_xtrain, cos_sim, k): #want to specify the size  \n",
    "    kNearest = {}   \n",
    "    # Have a dictionary stating the business and the neighbourhood, for ex. {2: 'A', 3: 'C', 6: 'C'}\n",
    "    for row in tqdm(range(len(cos_sim))):\n",
    "        possible_neighbours = []\n",
    "        for col in range(len(cos_sim[0])):\n",
    "            possible_neighbours.append((cos_sim[row][col], existing_neighbourhoods_xtrain[xtrain_comments_file.iloc[col,1]]))\n",
    "        possible_neighbours.sort(key=lambda x: x[0], reverse=True)\n",
    "  \n",
    "        votes = Counter()\n",
    "        for index in range(k):\n",
    "            votes[possible_neighbours[index][1]] += 1\n",
    "    \n",
    "        kNearest[test_file.iloc[row,1]] = votes.most_common(1)[0][0]\n",
    "    return kNearest\n",
    "        \n",
    "def Accuracy(kNearest_, existing_neighbourhood_dictionary):\n",
    "    total = len(kNearest_)\n",
    "    sum = 0\n",
    "    for key in kNearest_.keys():\n",
    "        if kNearest_[key] == existing_neighbourhood_dictionary[key]:\n",
    "            sum += 1\n",
    "    average = round(sum/total,5)\n",
    "    return average\n",
    "\n",
    "def official_neighbourhoods2(businesses_file):\n",
    "    neighbourhood_official = {}\n",
    "    for x in tqdm(range(businesses_file.shape[0])):\n",
    "        neighbourhood_official[(businesses_file.iloc[x,0])] = businesses_file.iloc[x,29]\n",
    "    return neighbourhood_official\n",
    "\n",
    "def kNearestData(test_file, xtrain_comments_file, existing_neighbourhoods_xtrain, cos_sim, k): #want to specify the size  \n",
    "    kNearest = {}   \n",
    "    hit_ratio_list = []\n",
    "    results_sf = []\n",
    "    # Have a dictionary stating the business and the neighbourhood, for ex. {2: 'A', 3: 'C', 6: 'C'}\n",
    "    for row in tqdm(range(len(cos_sim))):\n",
    "        possible_neighbours = []\n",
    "        for col in range(len(cos_sim[0])):\n",
    "             possible_neighbours.append((cos_sim[row][col], existing_neighbourhoods_xtrain[xtrain_comments_file.iloc[col,1]]))\n",
    "        possible_neighbours.sort(key=lambda x: x[0], reverse=True)\n",
    "        votes = Counter()\n",
    "        for index in range(k):\n",
    "            votes[possible_neighbours[index][1]] += 1         \n",
    "        kNearest[test_file.iloc[row,1]] = votes.most_common(1)[0][0]\n",
    "        if existing_neighbourhoods_xtrain[test_file.iloc[row,1]] in votes.keys():        \n",
    "            hit_ratio_list.append(round(votes[existing_neighbourhoods_xtrain[test_file.iloc[row,1]]]/k,4))\n",
    "            if existing_neighbourhoods_xtrain[test_file.iloc[row,1]] == votes.most_common(1)[0][0]:\n",
    "                results_sf.append(\"Success\")\n",
    "            else:\n",
    "                results_sf.append(\"Fail\")\n",
    "        else: \n",
    "            hit_ratio_list.append(0)\n",
    "            results_sf.append(\"Fail\")\n",
    "    return kNearest, votes, hit_ratio_list, results_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =  list(stopwords.words('english')) \n",
    "businesses = pd.read_csv(\"businesses (1).csv\")\n",
    "data = pd.read_csv('business_text_stripped.csv')\n",
    "toronto_map = gpd.read_file('Neighbourhoods.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topkDF_10000 = topkdocFreq(X_train, stop_words, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_xtrain_10000 = TFIDF_xtrain(X_train, topkDF_10000, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_10000 = TFIDF_test(X_train, X_test, topkDF_10000, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_10000 = cosineSimilarity(tfidf_xtrain_10000, tfidf_test_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "official_neighbourhoods_byName = official_neighbourhoods(businesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "official_neighbourhoods_byId = official_neighbourhoods2(businesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGroup_1, testGroup_2, testGroup_3, testGroup_4 = np.array_split(X_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_1, cos_sim_2, cos_sim_3, cos_sim_4 = np.array_split(cos_sim_10000, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kNearest_10000_1 = kNearestNeighbours(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_10000_1 = Accuracy(kNearest_10000_1, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_10000_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 2, k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_650_2 = kNearestNeighbours(testGroup_2, X_train, official_neighbourhoods_byName, cos_sim_2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_10000_2 = kNearest_650_2 #renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_10000_2 = Accuracy(kNearest_10000_2, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_10000_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 3, k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_10000_3 = kNearestNeighbours(testGroup_3, X_train, official_neighbourhoods_byName, cos_sim_3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_10000_3 = Accuracy(kNearest_10000_3, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_10000_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 4, k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_10000_4 = kNearestNeighbours(testGroup_4, X_train, official_neighbourhoods_byName, cos_sim_4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_10000_4 = Accuracy(kNearest_10000_4, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_10000_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Run \n",
    "### Group 1, k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_1_50, votes_1_50, hitRatio_1_50, results_1_50 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_50 = Accuracy(kNearest_1_50, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_1_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_50_counter = Counter(results_1_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_50_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_1_25, votes_1_25, hitRatio_1_25, results_1_25 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_25 = Accuracy(kNearest_1_25, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_1_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_25_counter = Counter(results_1_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_1_25_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitRatio_1_25_counter = Counter(hitRatio_1_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hitRatio_1_25_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_1_100, votes_1_100, hitRatio_1_100, results_1_100 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_100 = Accuracy(kNearest_1_100, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_100_counter = Counter(results_1_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_100_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitRatio_1_100_counter = Counter(hitRatio_1_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitRatio_1_100_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_1_200, votes_1_200, hitRatio_1_200, results_1_200 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_200 = Accuracy(kNearest_1_200, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_200_counter = Counter(results_1_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_200_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest_1_1500, votes_1_1500, hitRatio_1_1500, results_1_1500 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_1500 = Accuracy(kNearest_1_1500, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06207"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_1_1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2642/2642 [24:31<00:00,  2.01it/s] \n"
     ]
    }
   ],
   "source": [
    "kNearest_1_400, votes_1_400, hitRatio_1_400, results_1_400 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_400 = Accuracy(kNearest_1_400, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2642/2642 [27:12<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "kNearest_1_600, votes_1_600, hitRatio_1_600, results_1_600 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_600 = Accuracy(kNearest_1_600, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2642/2642 [39:53<00:00,  1.76it/s] \n"
     ]
    }
   ],
   "source": [
    "kNearest_1_800, votes_1_800, hitRatio_1_800, results_1_800 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_800 = Accuracy(kNearest_1_800, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2642/2642 [29:25<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "kNearest_1_1000, votes_1_1000, hitRatio_1_1000, results_1_1000 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_1000 = Accuracy(kNearest_1_1000, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2642/2642 [33:23<00:00,  1.97it/s] \n"
     ]
    }
   ],
   "source": [
    "kNearest_1_1200, votes_1_1200, hitRatio_1_1200, results_1_1200 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_1200 = Accuracy(kNearest_1_1200, official_neighbourhoods_byName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1, k = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2642/2642 [26:37<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "kNearest_1_1400, votes_1_1400, hitRatio_1_1400, results_1_1400 = kNearestData(testGroup_1, X_train, official_neighbourhoods_byName, cos_sim_1, 1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1_1400 = Accuracy(kNearest_1_1400, official_neighbourhoods_byName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
